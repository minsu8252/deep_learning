{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a1b2107",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14252bc7",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41e3f8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         149.62\n",
      "1           2.69\n",
      "2         378.66\n",
      "3         123.50\n",
      "4          69.99\n",
      "           ...  \n",
      "284802      0.77\n",
      "284803     24.79\n",
      "284804     67.88\n",
      "284805     10.00\n",
      "284806    217.00\n",
      "Name: Amount, Length: 284807, dtype: float64 \n",
      "\n",
      " <class 'pandas.core.series.Series'> \n",
      "\n",
      " (284807,)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "df = pd.read_csv('creditcard.csv')\n",
    "amount = df['Amount']\n",
    "\n",
    "print(f'{amount} \\n\\n {type(amount)} \\n\\n {amount.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1e59084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[149.62]\n",
      " [  2.69]\n",
      " [378.66]\n",
      " ...\n",
      " [ 67.88]\n",
      " [ 10.  ]\n",
      " [217.  ]] \n",
      "\n",
      " <class 'numpy.ndarray'> \n",
      "\n",
      " (284807, 1)\n"
     ]
    }
   ],
   "source": [
    "amount_val = amount.values # 시리즈의 value값만 가져옴\n",
    "amount = amount_val.reshape(-1,1) #amount.shape가 [1]이 없기때문에 reshape하여서 빈곳채움\n",
    "\n",
    "print(f'{amount} \\n\\n {type(amount)} \\n\\n {amount.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cd3bdec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24496426],\n",
       "       [-0.34247454],\n",
       "       [ 1.16068593],\n",
       "       ...,\n",
       "       [-0.0818393 ],\n",
       "       [-0.31324853],\n",
       "       [ 0.51435531]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler() #가져온거임\n",
    "\n",
    "scaler.fit(amount)\n",
    "amount_scaled = scaler.transform(amount)\n",
    "amount_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77d2a438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V22       V23       V24       V25       V26  \\\n",
       "0  0.098698  0.363787  ...  0.277838 -0.110474  0.066928  0.128539 -0.189115   \n",
       "1  0.085102 -0.255425  ... -0.638672  0.101288 -0.339846  0.167170  0.125895   \n",
       "2  0.247676 -1.514654  ...  0.771679  0.909412 -0.689281 -0.327642 -0.139097   \n",
       "3  0.377436 -1.387024  ...  0.005274 -0.190321 -1.175575  0.647376 -0.221929   \n",
       "4 -0.270533  0.817739  ...  0.798278 -0.137458  0.141267 -0.206010  0.502292   \n",
       "\n",
       "        V27       V28  Amount  Class  normAmount  \n",
       "0  0.133558 -0.021053  149.62      0    0.244964  \n",
       "1 -0.008983  0.014724    2.69      0   -0.342475  \n",
       "2 -0.055353 -0.059752  378.66      0    1.160686  \n",
       "3  0.062723  0.061458  123.50      0    0.140534  \n",
       "4  0.219422  0.215153   69.99      0   -0.073403  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['normAmount'] = amount_scaled\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25d4e7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.350151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.254117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.081839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.313249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.514355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V22       V23  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ...  0.277838 -0.110474   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.638672  0.101288   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.771679  0.909412   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ...  0.005274 -0.190321   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ...  0.798278 -0.137458   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.111864  1.014480   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.924384  0.012463   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.578229 -0.037501   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.800049 -0.163298   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.643078  0.376777   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \\\n",
       "0       0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62      0   \n",
       "1      -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69      0   \n",
       "2      -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0   \n",
       "3      -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50      0   \n",
       "4       0.141267 -0.206010  0.502292  0.219422  0.215153   69.99      0   \n",
       "...          ...       ...       ...       ...       ...     ...    ...   \n",
       "284802 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77      0   \n",
       "284803 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79      0   \n",
       "284804  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88      0   \n",
       "284805  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00      0   \n",
       "284806  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00      0   \n",
       "\n",
       "        normAmount  \n",
       "0         0.244964  \n",
       "1        -0.342475  \n",
       "2         1.160686  \n",
       "3         0.140534  \n",
       "4        -0.073403  \n",
       "...            ...  \n",
       "284802   -0.350151  \n",
       "284803   -0.254117  \n",
       "284804   -0.081839  \n",
       "284805   -0.313249  \n",
       "284806    0.514355  \n",
       "\n",
       "[284807 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터셋 확인\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8aab3e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "119bc5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>-0.350151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>-0.254117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>-0.081839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>-0.313249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0.514355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        normAmount  \n",
       "0         0.244964  \n",
       "1        -0.342475  \n",
       "2         1.160686  \n",
       "3         0.140534  \n",
       "4        -0.073403  \n",
       "...            ...  \n",
       "284802   -0.350151  \n",
       "284803   -0.254117  \n",
       "284804   -0.081839  \n",
       "284805   -0.313249  \n",
       "284806    0.514355  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x = df.iloc[:,df.columns != 'Class'].copy()\n",
    "df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3171be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "284802    0\n",
       "284803    0\n",
       "284804    0\n",
       "284805    0\n",
       "284806    0\n",
       "Name: Class, Length: 284807, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y = df['Class']\n",
    "df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a406faa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>1.475829</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>-0.350151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>-0.254117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>-0.081839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127434</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>-0.313249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382948</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>0.514355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V20       V21  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ...  0.251412 -0.018307   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.069083 -0.225775   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.524980  0.247998   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.208038 -0.108300   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ...  0.408542 -0.009431   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  1.475829  0.213454   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.059616  0.214205   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.001396  0.232045   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.127434  0.265245   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.382948  0.261057   \n",
       "\n",
       "             V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0       0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1      -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2       0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3       0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4       0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284802  0.111864  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731   \n",
       "284803  0.924384  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   \n",
       "284804  0.578229 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   \n",
       "284805  0.800049 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   \n",
       "284806  0.643078  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649   \n",
       "\n",
       "        normAmount  \n",
       "0         0.244964  \n",
       "1        -0.342475  \n",
       "2         1.160686  \n",
       "3         0.140534  \n",
       "4        -0.073403  \n",
       "...            ...  \n",
       "284802   -0.350151  \n",
       "284803   -0.254117  \n",
       "284804   -0.081839  \n",
       "284805   -0.313249  \n",
       "284806    0.514355  \n",
       "\n",
       "[284807 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x = df_x.drop('Amount',axis = 1).copy()\n",
    "df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a30337a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163152.0    36\n",
       "64947.0     26\n",
       "68780.0     25\n",
       "3767.0      21\n",
       "3770.0      20\n",
       "            ..\n",
       "81790.0      1\n",
       "54289.0      1\n",
       "37651.0      1\n",
       "112892.0     1\n",
       "119665.0     1\n",
       "Name: Time, Length: 124592, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x['Time'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85640dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>4.356170</td>\n",
       "      <td>...</td>\n",
       "      <td>1.475829</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>-0.350151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>-0.975926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>-0.254117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>-0.484782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>-0.081839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>-0.399126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127434</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>-0.313249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>-0.915427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382948</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>0.514355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               V1         V2        V3        V4        V5        V6  \\\n",
       "0       -1.359807  -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1        1.191857   0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2       -1.358354  -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3       -0.966272  -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4       -1.158233   0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "...           ...        ...       ...       ...       ...       ...   \n",
       "284802 -11.881118  10.071785 -9.834783 -2.066656 -5.364473 -2.606837   \n",
       "284803  -0.732789  -0.055080  2.035030 -0.738589  0.868229  1.058415   \n",
       "284804   1.919565  -0.301254 -3.249640 -0.557828  2.630515  3.031260   \n",
       "284805  -0.240440   0.530483  0.702510  0.689799 -0.377961  0.623708   \n",
       "284806  -0.533413  -0.189733  0.703337 -0.506271 -0.012546 -0.649617   \n",
       "\n",
       "              V7        V8        V9       V10  ...       V20       V21  \\\n",
       "0       0.239599  0.098698  0.363787  0.090794  ...  0.251412 -0.018307   \n",
       "1      -0.078803  0.085102 -0.255425 -0.166974  ... -0.069083 -0.225775   \n",
       "2       0.791461  0.247676 -1.514654  0.207643  ...  0.524980  0.247998   \n",
       "3       0.237609  0.377436 -1.387024 -0.054952  ... -0.208038 -0.108300   \n",
       "4       0.592941 -0.270533  0.817739  0.753074  ...  0.408542 -0.009431   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -4.918215  7.305334  1.914428  4.356170  ...  1.475829  0.213454   \n",
       "284803  0.024330  0.294869  0.584800 -0.975926  ...  0.059616  0.214205   \n",
       "284804 -0.296827  0.708417  0.432454 -0.484782  ...  0.001396  0.232045   \n",
       "284805 -0.686180  0.679145  0.392087 -0.399126  ...  0.127434  0.265245   \n",
       "284806  1.577006 -0.414650  0.486180 -0.915427  ...  0.382948  0.261057   \n",
       "\n",
       "             V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0       0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1      -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2       0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3       0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4       0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284802  0.111864  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731   \n",
       "284803  0.924384  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   \n",
       "284804  0.578229 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   \n",
       "284805  0.800049 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   \n",
       "284806  0.643078  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649   \n",
       "\n",
       "        normAmount  \n",
       "0         0.244964  \n",
       "1        -0.342475  \n",
       "2         1.160686  \n",
       "3         0.140534  \n",
       "4        -0.073403  \n",
       "...            ...  \n",
       "284802   -0.350151  \n",
       "284803   -0.254117  \n",
       "284804   -0.081839  \n",
       "284805   -0.313249  \n",
       "284806    0.514355  \n",
       "\n",
       "[284807 rows x 29 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x = df_x.drop('Time',axis = 1).copy()\n",
    "df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1545b165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>normAmount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>4.356170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>-0.350151</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>-0.975926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>-0.254117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>-0.484782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>-0.081839</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>-0.399126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>-0.313249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>-0.915427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>0.514355</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               V1         V2        V3        V4        V5        V6  \\\n",
       "0       -1.359807  -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1        1.191857   0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2       -1.358354  -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3       -0.966272  -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4       -1.158233   0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "...           ...        ...       ...       ...       ...       ...   \n",
       "284802 -11.881118  10.071785 -9.834783 -2.066656 -5.364473 -2.606837   \n",
       "284803  -0.732789  -0.055080  2.035030 -0.738589  0.868229  1.058415   \n",
       "284804   1.919565  -0.301254 -3.249640 -0.557828  2.630515  3.031260   \n",
       "284805  -0.240440   0.530483  0.702510  0.689799 -0.377961  0.623708   \n",
       "284806  -0.533413  -0.189733  0.703337 -0.506271 -0.012546 -0.649617   \n",
       "\n",
       "              V7        V8        V9       V10  ...       V21       V22  \\\n",
       "0       0.239599  0.098698  0.363787  0.090794  ... -0.018307  0.277838   \n",
       "1      -0.078803  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672   \n",
       "2       0.791461  0.247676 -1.514654  0.207643  ...  0.247998  0.771679   \n",
       "3       0.237609  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274   \n",
       "4       0.592941 -0.270533  0.817739  0.753074  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -4.918215  7.305334  1.914428  4.356170  ...  0.213454  0.111864   \n",
       "284803  0.024330  0.294869  0.584800 -0.975926  ...  0.214205  0.924384   \n",
       "284804 -0.296827  0.708417  0.432454 -0.484782  ...  0.232045  0.578229   \n",
       "284805 -0.686180  0.679145  0.392087 -0.399126  ...  0.265245  0.800049   \n",
       "284806  1.577006 -0.414650  0.486180 -0.915427  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "...          ...       ...       ...       ...       ...       ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649   \n",
       "\n",
       "        normAmount  Class  \n",
       "0         0.244964      0  \n",
       "1        -0.342475      0  \n",
       "2         1.160686      0  \n",
       "3         0.140534      0  \n",
       "4        -0.073403      0  \n",
       "...            ...    ...  \n",
       "284802   -0.350151      0  \n",
       "284803   -0.254117      0  \n",
       "284804   -0.081839      0  \n",
       "284805   -0.313249      0  \n",
       "284806    0.514355      0  \n",
       "\n",
       "[284807 rows x 30 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_x, df_y],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a783e1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('credit_test.csv')\n",
    "df = pd.read_csv('credit_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18b3330d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>normAmount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  normAmount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053    0.244964      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724   -0.342475      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752    1.160686      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458    0.140534      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   -0.073403      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf341a4",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1d7960",
   "metadata": {},
   "source": [
    "# Train set : Test set = 85 : 15 (4번)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8150d2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(242085, 29)\n",
      "(42722, 29)\n"
     ]
    }
   ],
   "source": [
    "X =df.values[:,0:29] #독립변수\n",
    "Y =df.values[:,29] #종속변수 , 30만\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(X,Y, test_size = 0.15) #85 : 15니까\n",
    "print(X_train.shape) # 85프로\n",
    "print(X_test.shape) #15프로"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f938800",
   "metadata": {},
   "source": [
    "# DNN 학습 및 저장 / 정확도, Loss 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce077f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.4658 - accuracy: 0.8723 - val_loss: 0.1492 - val_accuracy: 0.9981\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14923, saving model to ./credit\\01-0.1492.hdf5\n",
      "Epoch 2/1000\n",
      "163/163 [==============================] - 0s 853us/step - loss: 0.1186 - accuracy: 0.9984 - val_loss: 0.0660 - val_accuracy: 0.9981\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.14923 to 0.06598, saving model to ./credit\\02-0.0660.hdf5\n",
      "Epoch 3/1000\n",
      "163/163 [==============================] - 0s 843us/step - loss: 0.0581 - accuracy: 0.9983 - val_loss: 0.0414 - val_accuracy: 0.9981\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.06598 to 0.04144, saving model to ./credit\\03-0.0414.hdf5\n",
      "Epoch 4/1000\n",
      "163/163 [==============================] - 0s 845us/step - loss: 0.0374 - accuracy: 0.9986 - val_loss: 0.0296 - val_accuracy: 0.9990\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04144 to 0.02964, saving model to ./credit\\04-0.0296.hdf5\n",
      "Epoch 5/1000\n",
      "163/163 [==============================] - 0s 850us/step - loss: 0.0273 - accuracy: 0.9992 - val_loss: 0.0227 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02964 to 0.02273, saving model to ./credit\\05-0.0227.hdf5\n",
      "Epoch 6/1000\n",
      "163/163 [==============================] - 0s 852us/step - loss: 0.0214 - accuracy: 0.9993 - val_loss: 0.0183 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02273 to 0.01828, saving model to ./credit\\06-0.0183.hdf5\n",
      "Epoch 7/1000\n",
      "163/163 [==============================] - 0s 835us/step - loss: 0.0172 - accuracy: 0.9994 - val_loss: 0.0152 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01828 to 0.01518, saving model to ./credit\\07-0.0152.hdf5\n",
      "Epoch 8/1000\n",
      "163/163 [==============================] - 0s 841us/step - loss: 0.0147 - accuracy: 0.9992 - val_loss: 0.0130 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01518 to 0.01297, saving model to ./credit\\08-0.0130.hdf5\n",
      "Epoch 9/1000\n",
      "163/163 [==============================] - 0s 832us/step - loss: 0.0121 - accuracy: 0.9994 - val_loss: 0.0113 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01297 to 0.01130, saving model to ./credit\\09-0.0113.hdf5\n",
      "Epoch 10/1000\n",
      "163/163 [==============================] - 0s 843us/step - loss: 0.0107 - accuracy: 0.9994 - val_loss: 0.0100 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01130 to 0.01002, saving model to ./credit\\10-0.0100.hdf5\n",
      "Epoch 11/1000\n",
      "163/163 [==============================] - 0s 835us/step - loss: 0.0091 - accuracy: 0.9995 - val_loss: 0.0090 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01002 to 0.00904, saving model to ./credit\\11-0.0090.hdf5\n",
      "Epoch 12/1000\n",
      "163/163 [==============================] - 0s 838us/step - loss: 0.0082 - accuracy: 0.9994 - val_loss: 0.0082 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00904 to 0.00822, saving model to ./credit\\12-0.0082.hdf5\n",
      "Epoch 13/1000\n",
      "163/163 [==============================] - 0s 847us/step - loss: 0.0070 - accuracy: 0.9995 - val_loss: 0.0076 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00822 to 0.00763, saving model to ./credit\\13-0.0076.hdf5\n",
      "Epoch 14/1000\n",
      "163/163 [==============================] - 0s 842us/step - loss: 0.0072 - accuracy: 0.9994 - val_loss: 0.0071 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00763 to 0.00709, saving model to ./credit\\14-0.0071.hdf5\n",
      "Epoch 15/1000\n",
      "163/163 [==============================] - 0s 831us/step - loss: 0.0065 - accuracy: 0.9994 - val_loss: 0.0066 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00709 to 0.00660, saving model to ./credit\\15-0.0066.hdf5\n",
      "Epoch 16/1000\n",
      "163/163 [==============================] - 0s 844us/step - loss: 0.0059 - accuracy: 0.9995 - val_loss: 0.0062 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00660 to 0.00621, saving model to ./credit\\16-0.0062.hdf5\n",
      "Epoch 17/1000\n",
      "163/163 [==============================] - 0s 851us/step - loss: 0.0055 - accuracy: 0.9994 - val_loss: 0.0059 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00621 to 0.00585, saving model to ./credit\\17-0.0059.hdf5\n",
      "Epoch 18/1000\n",
      "163/163 [==============================] - 0s 834us/step - loss: 0.0050 - accuracy: 0.9995 - val_loss: 0.0056 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00585 to 0.00555, saving model to ./credit\\18-0.0056.hdf5\n",
      "Epoch 19/1000\n",
      "163/163 [==============================] - 0s 839us/step - loss: 0.0049 - accuracy: 0.9995 - val_loss: 0.0053 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00555 to 0.00529, saving model to ./credit\\19-0.0053.hdf5\n",
      "Epoch 20/1000\n",
      "163/163 [==============================] - 0s 843us/step - loss: 0.0042 - accuracy: 0.9996 - val_loss: 0.0050 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00529 to 0.00498, saving model to ./credit\\20-0.0050.hdf5\n",
      "Epoch 21/1000\n",
      "163/163 [==============================] - 0s 842us/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 0.0050 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00498\n",
      "Epoch 22/1000\n",
      "163/163 [==============================] - 0s 843us/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.0046 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00498 to 0.00461, saving model to ./credit\\22-0.0046.hdf5\n",
      "Epoch 23/1000\n",
      "163/163 [==============================] - 0s 911us/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.0045 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00461 to 0.00446, saving model to ./credit\\23-0.0045.hdf5\n",
      "Epoch 24/1000\n",
      "163/163 [==============================] - 0s 833us/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.0043 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00446 to 0.00431, saving model to ./credit\\24-0.0043.hdf5\n",
      "Epoch 25/1000\n",
      "163/163 [==============================] - 0s 838us/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.0043 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00431 to 0.00431, saving model to ./credit\\25-0.0043.hdf5\n",
      "Epoch 26/1000\n",
      "163/163 [==============================] - 0s 840us/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.0043 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00431 to 0.00427, saving model to ./credit\\26-0.0043.hdf5\n",
      "Epoch 27/1000\n",
      "163/163 [==============================] - 0s 856us/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00427 to 0.00395, saving model to ./credit\\27-0.0039.hdf5\n",
      "Epoch 28/1000\n",
      "163/163 [==============================] - 0s 846us/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.0038 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00395 to 0.00385, saving model to ./credit\\28-0.0038.hdf5\n",
      "Epoch 29/1000\n",
      "163/163 [==============================] - 0s 831us/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00385\n",
      "Epoch 30/1000\n",
      "163/163 [==============================] - 0s 843us/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.0037 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00385 to 0.00368, saving model to ./credit\\30-0.0037.hdf5\n",
      "Epoch 31/1000\n",
      "163/163 [==============================] - 0s 835us/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0036 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00368 to 0.00364, saving model to ./credit\\31-0.0036.hdf5\n",
      "Epoch 32/1000\n",
      "163/163 [==============================] - 0s 833us/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.0036 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00364 to 0.00361, saving model to ./credit\\32-0.0036.hdf5\n",
      "Epoch 33/1000\n",
      "163/163 [==============================] - 0s 840us/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.0036 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00361 to 0.00357, saving model to ./credit\\33-0.0036.hdf5\n",
      "Epoch 34/1000\n",
      "163/163 [==============================] - 0s 834us/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.0036 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00357\n",
      "Epoch 35/1000\n",
      "163/163 [==============================] - 0s 830us/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0035 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00357 to 0.00347, saving model to ./credit\\35-0.0035.hdf5\n",
      "Epoch 36/1000\n",
      "163/163 [==============================] - 0s 843us/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.0035 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00347\n",
      "Epoch 37/1000\n",
      "163/163 [==============================] - 0s 911us/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.0034 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00347 to 0.00340, saving model to ./credit\\37-0.0034.hdf5\n",
      "Epoch 38/1000\n",
      "163/163 [==============================] - 0s 853us/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00340\n",
      "Epoch 39/1000\n",
      "163/163 [==============================] - 0s 832us/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0033 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00340 to 0.00334, saving model to ./credit\\39-0.0033.hdf5\n",
      "Epoch 40/1000\n",
      "163/163 [==============================] - 0s 842us/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0033 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00334 to 0.00334, saving model to ./credit\\40-0.0033.hdf5\n",
      "Epoch 41/1000\n",
      "163/163 [==============================] - 0s 847us/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00334\n",
      "Epoch 42/1000\n",
      "163/163 [==============================] - 0s 836us/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0033 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00334 to 0.00330, saving model to ./credit\\42-0.0033.hdf5\n",
      "Epoch 43/1000\n",
      "163/163 [==============================] - 0s 840us/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0033 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00330\n",
      "Epoch 44/1000\n",
      "163/163 [==============================] - 0s 839us/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00330\n",
      "Epoch 45/1000\n",
      "163/163 [==============================] - 0s 847us/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.0034 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00330\n",
      "Epoch 46/1000\n",
      "163/163 [==============================] - 0s 841us/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0033 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00330\n",
      "Epoch 47/1000\n",
      "163/163 [==============================] - 0s 849us/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00330\n",
      "Epoch 48/1000\n",
      "163/163 [==============================] - 0s 856us/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0033 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00330 to 0.00330, saving model to ./credit\\48-0.0033.hdf5\n",
      "Epoch 49/1000\n",
      "163/163 [==============================] - 0s 849us/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.0035 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00330\n",
      "Epoch 50/1000\n",
      "163/163 [==============================] - 0s 847us/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00330\n",
      "Epoch 51/1000\n",
      "163/163 [==============================] - 0s 839us/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0033 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.00330\n",
      "Epoch 52/1000\n",
      "163/163 [==============================] - 0s 843us/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0035 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.00330\n",
      "Epoch 53/1000\n",
      "163/163 [==============================] - 0s 846us/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.00330\n",
      "Epoch 54/1000\n",
      "163/163 [==============================] - 0s 840us/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0033 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.00330\n",
      "Epoch 55/1000\n",
      "163/163 [==============================] - 0s 853us/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0033 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.00330\n",
      "Epoch 56/1000\n",
      "163/163 [==============================] - 0s 841us/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.00330\n",
      "Epoch 57/1000\n",
      "163/163 [==============================] - 0s 839us/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0032 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.00330 to 0.00324, saving model to ./credit\\57-0.0032.hdf5\n",
      "Epoch 58/1000\n",
      "163/163 [==============================] - 0s 843us/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00324\n",
      "Epoch 59/1000\n",
      "163/163 [==============================] - 0s 845us/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.00324\n",
      "Epoch 60/1000\n",
      "163/163 [==============================] - 0s 842us/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0033 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.00324\n",
      "Epoch 61/1000\n",
      "163/163 [==============================] - 0s 850us/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.00324\n",
      "Epoch 62/1000\n",
      "163/163 [==============================] - 0s 850us/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.00324\n",
      "Epoch 63/1000\n",
      "163/163 [==============================] - 0s 843us/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.00324\n",
      "Epoch 64/1000\n",
      "163/163 [==============================] - 0s 841us/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.00324\n",
      "Epoch 65/1000\n",
      "163/163 [==============================] - 0s 837us/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.00324\n",
      "Epoch 66/1000\n",
      "163/163 [==============================] - 0s 835us/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0035 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.00324\n",
      "Epoch 67/1000\n",
      "163/163 [==============================] - 0s 845us/step - loss: 9.8731e-04 - accuracy: 0.9999 - val_loss: 0.0033 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.00324\n",
      "Epoch 68/1000\n",
      "163/163 [==============================] - 0s 855us/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0035 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.00324\n",
      "Epoch 69/1000\n",
      "163/163 [==============================] - 0s 855us/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.00324\n",
      "Epoch 70/1000\n",
      "163/163 [==============================] - 0s 853us/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0036 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.00324\n",
      "Epoch 71/1000\n",
      "163/163 [==============================] - 0s 836us/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0035 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.00324\n",
      "Epoch 72/1000\n",
      "163/163 [==============================] - 0s 855us/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0043 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.00324\n",
      "Epoch 73/1000\n",
      "163/163 [==============================] - 0s 846us/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0037 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.00324\n",
      "Epoch 74/1000\n",
      "163/163 [==============================] - 0s 843us/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0035 - val_accuracy: 0.9994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00074: val_loss did not improve from 0.00324\n",
      "Epoch 75/1000\n",
      "163/163 [==============================] - 0s 843us/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0035 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.00324\n",
      "Epoch 76/1000\n",
      "163/163 [==============================] - 0s 843us/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0036 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.00324\n",
      "Epoch 77/1000\n",
      "163/163 [==============================] - 0s 844us/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0036 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.00324\n",
      "Epoch 78/1000\n",
      "163/163 [==============================] - 0s 846us/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0036 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.00324\n",
      "Epoch 79/1000\n",
      "163/163 [==============================] - 0s 831us/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0036 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.00324\n",
      "Epoch 80/1000\n",
      "163/163 [==============================] - 0s 843us/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0038 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.00324\n",
      "Epoch 81/1000\n",
      "163/163 [==============================] - 0s 854us/step - loss: 9.3265e-04 - accuracy: 0.9998 - val_loss: 0.0037 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.00324\n",
      "Epoch 82/1000\n",
      "163/163 [==============================] - 0s 837us/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0037 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.00324\n",
      "Epoch 83/1000\n",
      "163/163 [==============================] - 0s 856us/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0037 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.00324\n",
      "Epoch 84/1000\n",
      "163/163 [==============================] - 0s 857us/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.0036 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.00324\n",
      "Epoch 85/1000\n",
      "163/163 [==============================] - 0s 840us/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0038 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.00324\n",
      "Epoch 86/1000\n",
      "163/163 [==============================] - 0s 843us/step - loss: 9.1690e-04 - accuracy: 0.9999 - val_loss: 0.0037 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.00324\n",
      "Epoch 87/1000\n",
      "163/163 [==============================] - 0s 843us/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0037 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.00324\n",
      "Epoch 88/1000\n",
      "163/163 [==============================] - 0s 849us/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0039 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.00324\n",
      "Epoch 89/1000\n",
      "163/163 [==============================] - 0s 849us/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0037 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.00324\n",
      "Epoch 90/1000\n",
      "163/163 [==============================] - 0s 847us/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0037 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.00324\n",
      "Epoch 91/1000\n",
      "163/163 [==============================] - 0s 861us/step - loss: 9.6252e-04 - accuracy: 0.9998 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.00324\n",
      "Epoch 92/1000\n",
      "163/163 [==============================] - 0s 847us/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0037 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.00324\n",
      "Epoch 93/1000\n",
      "163/163 [==============================] - 0s 852us/step - loss: 8.8380e-04 - accuracy: 0.9998 - val_loss: 0.0038 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.00324\n",
      "Epoch 94/1000\n",
      "163/163 [==============================] - 0s 851us/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.00324\n",
      "Epoch 95/1000\n",
      "163/163 [==============================] - 0s 840us/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.00324\n",
      "Epoch 96/1000\n",
      "163/163 [==============================] - 0s 835us/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.00324\n",
      "Epoch 97/1000\n",
      "163/163 [==============================] - 0s 834us/step - loss: 9.8219e-04 - accuracy: 0.9999 - val_loss: 0.0037 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.00324\n",
      "Epoch 98/1000\n",
      "163/163 [==============================] - 0s 845us/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.00324\n",
      "Epoch 99/1000\n",
      "163/163 [==============================] - 0s 852us/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.00324\n",
      "Epoch 100/1000\n",
      "163/163 [==============================] - 0s 842us/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0041 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.00324\n",
      "Epoch 101/1000\n",
      "163/163 [==============================] - 0s 848us/step - loss: 8.5410e-04 - accuracy: 0.9998 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.00324\n",
      "Epoch 102/1000\n",
      "163/163 [==============================] - 0s 844us/step - loss: 9.6426e-04 - accuracy: 0.9999 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.00324\n",
      "Epoch 103/1000\n",
      "163/163 [==============================] - 0s 836us/step - loss: 9.8155e-04 - accuracy: 0.9998 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.00324\n",
      "Epoch 104/1000\n",
      "163/163 [==============================] - 0s 841us/step - loss: 9.3745e-04 - accuracy: 0.9998 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.00324\n",
      "Epoch 105/1000\n",
      "163/163 [==============================] - 0s 848us/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0038 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.00324\n",
      "Epoch 106/1000\n",
      "163/163 [==============================] - 0s 846us/step - loss: 9.9009e-04 - accuracy: 0.9998 - val_loss: 0.0038 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.00324\n",
      "Epoch 107/1000\n",
      "163/163 [==============================] - 0s 838us/step - loss: 9.6841e-04 - accuracy: 0.9998 - val_loss: 0.0038 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.00324\n",
      "Epoch 108/1000\n",
      "163/163 [==============================] - 0s 857us/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0037 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.00324\n",
      "Epoch 109/1000\n",
      "163/163 [==============================] - 0s 835us/step - loss: 7.4278e-04 - accuracy: 0.9999 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.00324\n",
      "Epoch 110/1000\n",
      "163/163 [==============================] - 0s 838us/step - loss: 7.1297e-04 - accuracy: 0.9999 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.00324\n",
      "Epoch 111/1000\n",
      "163/163 [==============================] - 0s 843us/step - loss: 5.5834e-04 - accuracy: 0.9999 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.00324\n",
      "Epoch 112/1000\n",
      "163/163 [==============================] - 0s 848us/step - loss: 5.2238e-04 - accuracy: 0.9999 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.00324\n",
      "Epoch 113/1000\n",
      "163/163 [==============================] - 0s 837us/step - loss: 8.0247e-04 - accuracy: 0.9999 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.00324\n",
      "Epoch 114/1000\n",
      "163/163 [==============================] - 0s 848us/step - loss: 8.8407e-04 - accuracy: 0.9998 - val_loss: 0.0038 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.00324\n",
      "Epoch 115/1000\n",
      "163/163 [==============================] - 0s 847us/step - loss: 7.9340e-04 - accuracy: 0.9999 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.00324\n",
      "Epoch 116/1000\n",
      "163/163 [==============================] - 0s 831us/step - loss: 8.6702e-04 - accuracy: 0.9998 - val_loss: 0.0038 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.00324\n",
      "Epoch 117/1000\n",
      "163/163 [==============================] - 0s 839us/step - loss: 9.3620e-04 - accuracy: 0.9998 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.00324\n",
      "Epoch 118/1000\n",
      "163/163 [==============================] - 0s 843us/step - loss: 9.2695e-04 - accuracy: 0.9998 - val_loss: 0.0038 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.00324\n",
      "Epoch 119/1000\n",
      "163/163 [==============================] - 0s 846us/step - loss: 8.1818e-04 - accuracy: 0.9999 - val_loss: 0.0038 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.00324\n",
      "Epoch 120/1000\n",
      "163/163 [==============================] - 0s 842us/step - loss: 6.2455e-04 - accuracy: 0.9999 - val_loss: 0.0038 - val_accuracy: 0.9995\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.00324\n",
      "Epoch 121/1000\n",
      "163/163 [==============================] - 0s 853us/step - loss: 7.7693e-04 - accuracy: 0.9998 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.00324\n",
      "Epoch 122/1000\n",
      "163/163 [==============================] - 0s 840us/step - loss: 8.9084e-04 - accuracy: 0.9998 - val_loss: 0.0038 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.00324\n",
      "Epoch 123/1000\n",
      "163/163 [==============================] - 0s 840us/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.00324\n",
      "Epoch 124/1000\n",
      "163/163 [==============================] - 0s 841us/step - loss: 8.3133e-04 - accuracy: 0.9998 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.00324\n",
      "Epoch 125/1000\n",
      "163/163 [==============================] - 0s 845us/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.00324\n",
      "Epoch 126/1000\n",
      "163/163 [==============================] - 0s 850us/step - loss: 8.4208e-04 - accuracy: 0.9999 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.00324\n",
      "Epoch 127/1000\n",
      "163/163 [==============================] - 0s 846us/step - loss: 7.6742e-04 - accuracy: 0.9999 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.00324\n",
      "Epoch 128/1000\n",
      "163/163 [==============================] - 0s 848us/step - loss: 6.7776e-04 - accuracy: 0.9999 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.00324\n",
      "Epoch 129/1000\n",
      "163/163 [==============================] - 0s 849us/step - loss: 7.3994e-04 - accuracy: 0.9999 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.00324\n",
      "Epoch 130/1000\n",
      "163/163 [==============================] - 0s 843us/step - loss: 9.4794e-04 - accuracy: 0.9999 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.00324\n",
      "Epoch 131/1000\n",
      "163/163 [==============================] - 0s 839us/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.00324\n",
      "Epoch 132/1000\n",
      "163/163 [==============================] - 0s 850us/step - loss: 8.1024e-04 - accuracy: 0.9999 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.00324\n",
      "Epoch 133/1000\n",
      "163/163 [==============================] - 0s 844us/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.00324\n",
      "Epoch 134/1000\n",
      "163/163 [==============================] - 0s 850us/step - loss: 9.3165e-04 - accuracy: 0.9998 - val_loss: 0.0041 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.00324\n",
      "Epoch 135/1000\n",
      "163/163 [==============================] - 0s 846us/step - loss: 9.0863e-04 - accuracy: 0.9998 - val_loss: 0.0038 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.00324\n",
      "Epoch 136/1000\n",
      "163/163 [==============================] - 0s 842us/step - loss: 9.3060e-04 - accuracy: 0.9998 - val_loss: 0.0041 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.00324\n",
      "Epoch 137/1000\n",
      "163/163 [==============================] - 0s 856us/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0041 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.00324\n",
      "Epoch 138/1000\n",
      "163/163 [==============================] - 0s 845us/step - loss: 7.6268e-04 - accuracy: 0.9998 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.00324\n",
      "Epoch 139/1000\n",
      "163/163 [==============================] - 0s 851us/step - loss: 7.8071e-04 - accuracy: 0.9999 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.00324\n",
      "Epoch 140/1000\n",
      "163/163 [==============================] - 0s 848us/step - loss: 5.7487e-04 - accuracy: 0.9999 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.00324\n",
      "Epoch 141/1000\n",
      "163/163 [==============================] - 0s 835us/step - loss: 8.2347e-04 - accuracy: 0.9999 - val_loss: 0.0041 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.00324\n",
      "Epoch 142/1000\n",
      "163/163 [==============================] - 0s 841us/step - loss: 6.0920e-04 - accuracy: 0.9999 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.00324\n",
      "Epoch 143/1000\n",
      "163/163 [==============================] - 0s 854us/step - loss: 5.8456e-04 - accuracy: 0.9999 - val_loss: 0.0042 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.00324\n",
      "Epoch 144/1000\n",
      "163/163 [==============================] - 0s 841us/step - loss: 8.3954e-04 - accuracy: 0.9998 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.00324\n",
      "Epoch 145/1000\n",
      "163/163 [==============================] - 0s 850us/step - loss: 8.4183e-04 - accuracy: 0.9998 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.00324\n",
      "Epoch 146/1000\n",
      "163/163 [==============================] - 0s 836us/step - loss: 6.8471e-04 - accuracy: 0.9999 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.00324\n",
      "Epoch 147/1000\n",
      "163/163 [==============================] - 0s 838us/step - loss: 5.5570e-04 - accuracy: 0.9999 - val_loss: 0.0042 - val_accuracy: 0.9993\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.00324\n",
      "Epoch 148/1000\n",
      "163/163 [==============================] - 0s 851us/step - loss: 6.5159e-04 - accuracy: 0.9999 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.00324\n",
      "Epoch 149/1000\n",
      "163/163 [==============================] - 0s 838us/step - loss: 8.6137e-04 - accuracy: 0.9999 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.00324\n",
      "Epoch 150/1000\n",
      "163/163 [==============================] - 0s 848us/step - loss: 7.1572e-04 - accuracy: 0.9999 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.00324\n",
      "Epoch 151/1000\n",
      "163/163 [==============================] - 0s 842us/step - loss: 8.4836e-04 - accuracy: 0.9998 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.00324\n",
      "Epoch 152/1000\n",
      "163/163 [==============================] - 0s 848us/step - loss: 6.9048e-04 - accuracy: 0.9999 - val_loss: 0.0041 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.00324\n",
      "Epoch 153/1000\n",
      "163/163 [==============================] - 0s 843us/step - loss: 8.6188e-04 - accuracy: 0.9998 - val_loss: 0.0041 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.00324\n",
      "Epoch 154/1000\n",
      "163/163 [==============================] - 0s 845us/step - loss: 8.6414e-04 - accuracy: 0.9999 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.00324\n",
      "Epoch 155/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 853us/step - loss: 8.9480e-04 - accuracy: 0.9999 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.00324\n",
      "Epoch 156/1000\n",
      "163/163 [==============================] - 0s 887us/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0041 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.00324\n",
      "Epoch 157/1000\n",
      "163/163 [==============================] - 0s 874us/step - loss: 6.3255e-04 - accuracy: 0.9999 - val_loss: 0.0042 - val_accuracy: 0.9994\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.00324\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 14)                420       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 105       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 32        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 562\n",
      "Trainable params: 562\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#모델 설정\n",
    "model = Sequential()\n",
    "model.add(Dense(14, activation='tanh', input_dim=X.shape[1]))\n",
    "model.add(Dense(7, activation='relu'))\n",
    "model.add(Dense(4, activation='tanh'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#모델 컴파일\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics= ['accuracy'])\n",
    "\n",
    "# #모델 저장 폴더 지정\n",
    "MODEL_DIR='./credit/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "\n",
    "# #모델 저장 방법\n",
    "modelpath = './credit/{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "checkpointer =  ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    \n",
    "# 학습 조기 종료 , callbacks=[checkpointer, early_stopping_callback]\n",
    "early_stopping_callback= EarlyStopping(monitor='val_loss', patience=100)\n",
    "\n",
    "\n",
    "#모델 학습\n",
    "history = model.fit(X_train, Y_train ,validation_split=0.33, epochs=1000, batch_size=1000,\n",
    "                    callbacks=[checkpointer, early_stopping_callback])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b2cdde9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 반복횟수에 따른 정확도 및 loss를 그래프로 확인\n",
    "y_vloss = history.history['val_loss']\n",
    "y_acc = history.history['accuracy']\n",
    "\n",
    "x_len = np.arange(len(y_acc))\n",
    "\n",
    "\n",
    "plt.plot(x_len, y_vloss, 'o', c='red',markersize=3)\n",
    "plt.plot(x_len, y_acc, 'o', c='blue',markersize=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d59f38b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1336/1336 [==============================] - 1s 307us/step - loss: 0.0034 - accuracy: 0.9994\n",
      "[0.003351078135892749, 0.9993914365768433]\n",
      "가져올 데이터 번호1\n",
      "신용카드를 부정사용 확률은 0.013536214828491211%입니다.\n"
     ]
    }
   ],
   "source": [
    "#학습기 불러오기\n",
    "from keras.models import load_model\n",
    "# model.save('09-0.0902.hdf5')\n",
    "model= load_model('./credit/57-0.0032.hdf5')\n",
    "\n",
    "\n",
    "#평가\n",
    "print(model.evaluate(X_test,Y_test))\n",
    "\n",
    "#예측\n",
    "prediction = model.predict(X_test)\n",
    "# print(prediction)\n",
    "부정자용자 =int(input('가져올 데이터 번호'))\n",
    "부정사용 = prediction[부정자용자]\n",
    "p=부정사용[0]*100\n",
    "print(f'신용카드를 부정사용 확률은 {p}%입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2c611cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42722, 1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_t = np.round(prediction)\n",
    "y_pred_t = y_pred_t.astype(int)\n",
    "y_pred_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3934961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_t = Y_test.astype(int)\n",
    "Y_test_t = Y_test_t.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ae3224c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42722, 1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0599a4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2111,  5621,  9258,  9259,  9269, 11001, 11344, 15679, 16192,\n",
       "       16783, 19925, 20713, 23829, 25980, 28689, 32165, 32900, 34054,\n",
       "       37266, 38521, 39874, 40174, 40482, 41431, 41712, 42424],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측값과 실제값 다른것들만 들고와서 보여주기위함\n",
    "miss = np.where(Y_test_t != y_pred_t)[0]\n",
    "miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8ea49c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 몇개 잘못 분류 했나?\n",
    "len(miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5d4ba0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True값은 : [1]인데, Predic값은 : [0]이다\n"
     ]
    }
   ],
   "source": [
    "i=np.random.choice(miss)\n",
    "print(\"True값은 : %s인데, Predic값은 : %s이다\"%(Y_test_t[i],y_pred_t[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce0a6fc",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38c3d4a",
   "metadata": {},
   "source": [
    "# 0 : 492개, 1: 492개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5ecccf4d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()\n",
    "# 출력층 몇개 있는지 확인하려고 클래스값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "03f66674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>normAmount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109157</th>\n",
       "      <td>-0.652829</td>\n",
       "      <td>1.122547</td>\n",
       "      <td>0.744271</td>\n",
       "      <td>0.764912</td>\n",
       "      <td>-0.139230</td>\n",
       "      <td>-0.204473</td>\n",
       "      <td>0.564068</td>\n",
       "      <td>0.402104</td>\n",
       "      <td>-1.099772</td>\n",
       "      <td>-0.329863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265884</td>\n",
       "      <td>0.551817</td>\n",
       "      <td>-0.024144</td>\n",
       "      <td>0.013799</td>\n",
       "      <td>-0.193939</td>\n",
       "      <td>-0.331876</td>\n",
       "      <td>0.023635</td>\n",
       "      <td>0.092980</td>\n",
       "      <td>-0.079560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126193</th>\n",
       "      <td>-3.339192</td>\n",
       "      <td>1.370165</td>\n",
       "      <td>1.067984</td>\n",
       "      <td>-1.500224</td>\n",
       "      <td>-0.287427</td>\n",
       "      <td>0.172767</td>\n",
       "      <td>0.816022</td>\n",
       "      <td>-0.375759</td>\n",
       "      <td>0.778981</td>\n",
       "      <td>4.451948</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.250027</td>\n",
       "      <td>-1.383554</td>\n",
       "      <td>-0.211176</td>\n",
       "      <td>-0.397625</td>\n",
       "      <td>0.352532</td>\n",
       "      <td>0.021993</td>\n",
       "      <td>0.276908</td>\n",
       "      <td>0.054283</td>\n",
       "      <td>-0.153325</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253824</th>\n",
       "      <td>-0.670594</td>\n",
       "      <td>0.394768</td>\n",
       "      <td>0.923089</td>\n",
       "      <td>-0.752429</td>\n",
       "      <td>1.504524</td>\n",
       "      <td>0.708785</td>\n",
       "      <td>1.111056</td>\n",
       "      <td>-0.277891</td>\n",
       "      <td>0.319910</td>\n",
       "      <td>-0.297117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194003</td>\n",
       "      <td>1.173429</td>\n",
       "      <td>-0.462605</td>\n",
       "      <td>-0.935719</td>\n",
       "      <td>-0.027568</td>\n",
       "      <td>0.743513</td>\n",
       "      <td>-0.476945</td>\n",
       "      <td>-0.327464</td>\n",
       "      <td>-0.300934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80761</th>\n",
       "      <td>-1.795105</td>\n",
       "      <td>-1.494352</td>\n",
       "      <td>-0.537945</td>\n",
       "      <td>0.863900</td>\n",
       "      <td>-1.553549</td>\n",
       "      <td>1.518933</td>\n",
       "      <td>3.948610</td>\n",
       "      <td>-0.120538</td>\n",
       "      <td>-1.301061</td>\n",
       "      <td>-1.010590</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777665</td>\n",
       "      <td>0.705091</td>\n",
       "      <td>1.978397</td>\n",
       "      <td>-0.395184</td>\n",
       "      <td>-0.092714</td>\n",
       "      <td>-0.432663</td>\n",
       "      <td>-0.119388</td>\n",
       "      <td>0.224242</td>\n",
       "      <td>3.206027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268908</th>\n",
       "      <td>2.078239</td>\n",
       "      <td>0.144335</td>\n",
       "      <td>-1.729059</td>\n",
       "      <td>0.406886</td>\n",
       "      <td>0.426321</td>\n",
       "      <td>-0.854552</td>\n",
       "      <td>0.173452</td>\n",
       "      <td>-0.223779</td>\n",
       "      <td>0.522796</td>\n",
       "      <td>-0.373312</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.369914</td>\n",
       "      <td>-0.968218</td>\n",
       "      <td>0.335007</td>\n",
       "      <td>0.477426</td>\n",
       "      <td>-0.256684</td>\n",
       "      <td>0.175501</td>\n",
       "      <td>-0.063895</td>\n",
       "      <td>-0.031313</td>\n",
       "      <td>-0.345313</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226524</th>\n",
       "      <td>-0.385187</td>\n",
       "      <td>1.145826</td>\n",
       "      <td>-0.486830</td>\n",
       "      <td>-1.511339</td>\n",
       "      <td>1.828797</td>\n",
       "      <td>-0.972461</td>\n",
       "      <td>2.314604</td>\n",
       "      <td>-1.188300</td>\n",
       "      <td>0.468980</td>\n",
       "      <td>1.381381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054596</td>\n",
       "      <td>1.029494</td>\n",
       "      <td>-0.337401</td>\n",
       "      <td>0.802903</td>\n",
       "      <td>-0.357170</td>\n",
       "      <td>-0.096630</td>\n",
       "      <td>-0.330168</td>\n",
       "      <td>-0.495440</td>\n",
       "      <td>-0.333199</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155342</th>\n",
       "      <td>-1.050018</td>\n",
       "      <td>0.735897</td>\n",
       "      <td>2.133696</td>\n",
       "      <td>-0.304232</td>\n",
       "      <td>0.377698</td>\n",
       "      <td>0.217087</td>\n",
       "      <td>0.404572</td>\n",
       "      <td>-0.208117</td>\n",
       "      <td>1.503811</td>\n",
       "      <td>-0.633820</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.260881</td>\n",
       "      <td>-0.341430</td>\n",
       "      <td>-0.185945</td>\n",
       "      <td>-0.501097</td>\n",
       "      <td>0.272478</td>\n",
       "      <td>-0.751736</td>\n",
       "      <td>-0.465140</td>\n",
       "      <td>-0.135215</td>\n",
       "      <td>-0.315687</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227379</th>\n",
       "      <td>2.014456</td>\n",
       "      <td>-0.928607</td>\n",
       "      <td>-0.433808</td>\n",
       "      <td>-0.541926</td>\n",
       "      <td>-0.882319</td>\n",
       "      <td>-0.014980</td>\n",
       "      <td>-0.911860</td>\n",
       "      <td>0.057144</td>\n",
       "      <td>-0.423906</td>\n",
       "      <td>0.932040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.546713</td>\n",
       "      <td>-1.117669</td>\n",
       "      <td>0.512598</td>\n",
       "      <td>0.730789</td>\n",
       "      <td>-0.760182</td>\n",
       "      <td>0.172004</td>\n",
       "      <td>-0.023472</td>\n",
       "      <td>-0.033804</td>\n",
       "      <td>-0.181392</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16813</th>\n",
       "      <td>-0.859298</td>\n",
       "      <td>1.739932</td>\n",
       "      <td>-2.681852</td>\n",
       "      <td>0.903709</td>\n",
       "      <td>1.735308</td>\n",
       "      <td>-0.460571</td>\n",
       "      <td>2.095634</td>\n",
       "      <td>-1.071132</td>\n",
       "      <td>2.328420</td>\n",
       "      <td>2.241297</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.894938</td>\n",
       "      <td>-0.441214</td>\n",
       "      <td>0.050608</td>\n",
       "      <td>-1.756554</td>\n",
       "      <td>-0.128400</td>\n",
       "      <td>-0.429088</td>\n",
       "      <td>-0.334002</td>\n",
       "      <td>-0.822554</td>\n",
       "      <td>0.006558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238907</th>\n",
       "      <td>1.918736</td>\n",
       "      <td>0.602902</td>\n",
       "      <td>-1.579360</td>\n",
       "      <td>3.604288</td>\n",
       "      <td>1.089076</td>\n",
       "      <td>0.026455</td>\n",
       "      <td>0.604443</td>\n",
       "      <td>-0.057641</td>\n",
       "      <td>-1.444580</td>\n",
       "      <td>1.717885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159504</td>\n",
       "      <td>0.394829</td>\n",
       "      <td>0.025920</td>\n",
       "      <td>0.672106</td>\n",
       "      <td>0.343012</td>\n",
       "      <td>0.125584</td>\n",
       "      <td>-0.094508</td>\n",
       "      <td>-0.072376</td>\n",
       "      <td>-0.292738</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>492 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "109157 -0.652829  1.122547  0.744271  0.764912 -0.139230 -0.204473  0.564068   \n",
       "126193 -3.339192  1.370165  1.067984 -1.500224 -0.287427  0.172767  0.816022   \n",
       "253824 -0.670594  0.394768  0.923089 -0.752429  1.504524  0.708785  1.111056   \n",
       "80761  -1.795105 -1.494352 -0.537945  0.863900 -1.553549  1.518933  3.948610   \n",
       "268908  2.078239  0.144335 -1.729059  0.406886  0.426321 -0.854552  0.173452   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "226524 -0.385187  1.145826 -0.486830 -1.511339  1.828797 -0.972461  2.314604   \n",
       "155342 -1.050018  0.735897  2.133696 -0.304232  0.377698  0.217087  0.404572   \n",
       "227379  2.014456 -0.928607 -0.433808 -0.541926 -0.882319 -0.014980 -0.911860   \n",
       "16813  -0.859298  1.739932 -2.681852  0.903709  1.735308 -0.460571  2.095634   \n",
       "238907  1.918736  0.602902 -1.579360  3.604288  1.089076  0.026455  0.604443   \n",
       "\n",
       "              V8        V9       V10  ...       V21       V22       V23  \\\n",
       "109157  0.402104 -1.099772 -0.329863  ...  0.265884  0.551817 -0.024144   \n",
       "126193 -0.375759  0.778981  4.451948  ... -1.250027 -1.383554 -0.211176   \n",
       "253824 -0.277891  0.319910 -0.297117  ...  0.194003  1.173429 -0.462605   \n",
       "80761  -0.120538 -1.301061 -1.010590  ...  0.777665  0.705091  1.978397   \n",
       "268908 -0.223779  0.522796 -0.373312  ... -0.369914 -0.968218  0.335007   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "226524 -1.188300  0.468980  1.381381  ...  0.054596  1.029494 -0.337401   \n",
       "155342 -0.208117  1.503811 -0.633820  ... -0.260881 -0.341430 -0.185945   \n",
       "227379  0.057144 -0.423906  0.932040  ... -0.546713 -1.117669  0.512598   \n",
       "16813  -1.071132  2.328420  2.241297  ... -0.894938 -0.441214  0.050608   \n",
       "238907 -0.057641 -1.444580  1.717885  ...  0.159504  0.394829  0.025920   \n",
       "\n",
       "             V24       V25       V26       V27       V28  normAmount  Class  \n",
       "109157  0.013799 -0.193939 -0.331876  0.023635  0.092980   -0.079560      0  \n",
       "126193 -0.397625  0.352532  0.021993  0.276908  0.054283   -0.153325      0  \n",
       "253824 -0.935719 -0.027568  0.743513 -0.476945 -0.327464   -0.300934      0  \n",
       "80761  -0.395184 -0.092714 -0.432663 -0.119388  0.224242    3.206027      0  \n",
       "268908  0.477426 -0.256684  0.175501 -0.063895 -0.031313   -0.345313      0  \n",
       "...          ...       ...       ...       ...       ...         ...    ...  \n",
       "226524  0.802903 -0.357170 -0.096630 -0.330168 -0.495440   -0.333199      0  \n",
       "155342 -0.501097  0.272478 -0.751736 -0.465140 -0.135215   -0.315687      0  \n",
       "227379  0.730789 -0.760182  0.172004 -0.023472 -0.033804   -0.181392      0  \n",
       "16813  -1.756554 -0.128400 -0.429088 -0.334002 -0.822554    0.006558      0  \n",
       "238907  0.672106  0.343012  0.125584 -0.094508 -0.072376   -0.292738      0  \n",
       "\n",
       "[492 rows x 30 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_0 = df[df['Class'] == 0].sample(492)\n",
    "df_class_0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6e828163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_0['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2114f96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>normAmount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>-2.772272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517232</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>-0.353229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>-0.838587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>1.761758</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>-1.525412</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294166</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>0.606031</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>-4.801637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573574</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>-0.117342</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>1.234235</td>\n",
       "      <td>3.019740</td>\n",
       "      <td>-4.304597</td>\n",
       "      <td>4.732795</td>\n",
       "      <td>3.624201</td>\n",
       "      <td>-1.357746</td>\n",
       "      <td>1.713445</td>\n",
       "      <td>-0.496358</td>\n",
       "      <td>-1.282858</td>\n",
       "      <td>-2.447469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379068</td>\n",
       "      <td>-0.704181</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>-1.632653</td>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.566797</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>-0.349231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279863</th>\n",
       "      <td>-1.927883</td>\n",
       "      <td>1.125653</td>\n",
       "      <td>-4.518331</td>\n",
       "      <td>1.749293</td>\n",
       "      <td>-1.566487</td>\n",
       "      <td>-2.010494</td>\n",
       "      <td>-0.882850</td>\n",
       "      <td>0.697211</td>\n",
       "      <td>-2.064945</td>\n",
       "      <td>-5.587794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.778584</td>\n",
       "      <td>-0.319189</td>\n",
       "      <td>0.639419</td>\n",
       "      <td>-0.294885</td>\n",
       "      <td>0.537503</td>\n",
       "      <td>0.788395</td>\n",
       "      <td>0.292680</td>\n",
       "      <td>0.147968</td>\n",
       "      <td>1.206024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280143</th>\n",
       "      <td>1.378559</td>\n",
       "      <td>1.289381</td>\n",
       "      <td>-5.004247</td>\n",
       "      <td>1.411850</td>\n",
       "      <td>0.442581</td>\n",
       "      <td>-1.326536</td>\n",
       "      <td>-1.413170</td>\n",
       "      <td>0.248525</td>\n",
       "      <td>-1.127396</td>\n",
       "      <td>-3.232153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370612</td>\n",
       "      <td>0.028234</td>\n",
       "      <td>-0.145640</td>\n",
       "      <td>-0.081049</td>\n",
       "      <td>0.521875</td>\n",
       "      <td>0.739467</td>\n",
       "      <td>0.389152</td>\n",
       "      <td>0.186637</td>\n",
       "      <td>-0.350191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280149</th>\n",
       "      <td>-0.676143</td>\n",
       "      <td>1.126366</td>\n",
       "      <td>-2.213700</td>\n",
       "      <td>0.468308</td>\n",
       "      <td>-1.120541</td>\n",
       "      <td>-0.003346</td>\n",
       "      <td>-2.234739</td>\n",
       "      <td>1.210158</td>\n",
       "      <td>-0.652250</td>\n",
       "      <td>-3.463891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751826</td>\n",
       "      <td>0.834108</td>\n",
       "      <td>0.190944</td>\n",
       "      <td>0.032070</td>\n",
       "      <td>-0.739695</td>\n",
       "      <td>0.471111</td>\n",
       "      <td>0.385107</td>\n",
       "      <td>0.194361</td>\n",
       "      <td>-0.041818</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281144</th>\n",
       "      <td>-3.113832</td>\n",
       "      <td>0.585864</td>\n",
       "      <td>-5.399730</td>\n",
       "      <td>1.817092</td>\n",
       "      <td>-0.840618</td>\n",
       "      <td>-2.943548</td>\n",
       "      <td>-2.208002</td>\n",
       "      <td>1.058733</td>\n",
       "      <td>-1.632333</td>\n",
       "      <td>-5.245984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583276</td>\n",
       "      <td>-0.269209</td>\n",
       "      <td>-0.456108</td>\n",
       "      <td>-0.183659</td>\n",
       "      <td>-0.328168</td>\n",
       "      <td>0.606116</td>\n",
       "      <td>0.884876</td>\n",
       "      <td>-0.253700</td>\n",
       "      <td>0.626302</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281674</th>\n",
       "      <td>1.991976</td>\n",
       "      <td>0.158476</td>\n",
       "      <td>-2.583441</td>\n",
       "      <td>0.408670</td>\n",
       "      <td>1.151147</td>\n",
       "      <td>-0.096695</td>\n",
       "      <td>0.223050</td>\n",
       "      <td>-0.068384</td>\n",
       "      <td>0.577829</td>\n",
       "      <td>-0.888722</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164350</td>\n",
       "      <td>-0.295135</td>\n",
       "      <td>-0.072173</td>\n",
       "      <td>-0.450261</td>\n",
       "      <td>0.313267</td>\n",
       "      <td>-0.289617</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>-0.015309</td>\n",
       "      <td>-0.183191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>492 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "541    -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545 -2.537387   \n",
       "623    -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823  0.325574   \n",
       "4920   -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788  0.562320   \n",
       "6108   -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536 -3.496197   \n",
       "6329    1.234235  3.019740 -4.304597  4.732795  3.624201 -1.357746  1.713445   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "279863 -1.927883  1.125653 -4.518331  1.749293 -1.566487 -2.010494 -0.882850   \n",
       "280143  1.378559  1.289381 -5.004247  1.411850  0.442581 -1.326536 -1.413170   \n",
       "280149 -0.676143  1.126366 -2.213700  0.468308 -1.120541 -0.003346 -2.234739   \n",
       "281144 -3.113832  0.585864 -5.399730  1.817092 -0.840618 -2.943548 -2.208002   \n",
       "281674  1.991976  0.158476 -2.583441  0.408670  1.151147 -0.096695  0.223050   \n",
       "\n",
       "              V8        V9       V10  ...       V21       V22       V23  \\\n",
       "541     1.391657 -2.770089 -2.772272  ...  0.517232 -0.035049 -0.465211   \n",
       "623    -0.067794 -0.270953 -0.838587  ...  0.661696  0.435477  1.375966   \n",
       "4920   -0.399147 -0.238253 -1.525412  ... -0.294166 -0.932391  0.172726   \n",
       "6108   -0.248778 -0.247768 -4.801637  ...  0.573574  0.176968 -0.436207   \n",
       "6329   -0.496358 -1.282858 -2.447469  ... -0.379068 -0.704181 -0.656805   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "279863  0.697211 -2.064945 -5.587794  ...  0.778584 -0.319189  0.639419   \n",
       "280143  0.248525 -1.127396 -3.232153  ...  0.370612  0.028234 -0.145640   \n",
       "280149  1.210158 -0.652250 -3.463891  ...  0.751826  0.834108  0.190944   \n",
       "281144  1.058733 -1.632333 -5.245984  ...  0.583276 -0.269209 -0.456108   \n",
       "281674 -0.068384  0.577829 -0.888722  ... -0.164350 -0.295135 -0.072173   \n",
       "\n",
       "             V24       V25       V26       V27       V28  normAmount  Class  \n",
       "541     0.320198  0.044519  0.177840  0.261145 -0.143276   -0.353229      1  \n",
       "623    -0.293803  0.279798 -0.145362 -0.252773  0.035764    1.761758      1  \n",
       "4920   -0.087330 -0.156114 -0.542628  0.039566 -0.153029    0.606031      1  \n",
       "6108   -0.053502  0.252405 -0.657488 -0.827136  0.849573   -0.117342      1  \n",
       "6329   -1.632653  1.488901  0.566797 -0.010016  0.146793   -0.349231      1  \n",
       "...          ...       ...       ...       ...       ...         ...    ...  \n",
       "279863 -0.294885  0.537503  0.788395  0.292680  0.147968    1.206024      1  \n",
       "280143 -0.081049  0.521875  0.739467  0.389152  0.186637   -0.350191      1  \n",
       "280149  0.032070 -0.739695  0.471111  0.385107  0.194361   -0.041818      1  \n",
       "281144 -0.183659 -0.328168  0.606116  0.884876 -0.253700    0.626302      1  \n",
       "281674 -0.450261  0.313267 -0.289617  0.002988 -0.015309   -0.183191      1  \n",
       "\n",
       "[492 rows x 30 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_1 = df[df['Class'] == 1]\n",
    "df_class_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "dcc00bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_1['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "51aa2f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>normAmount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109157</th>\n",
       "      <td>-0.652829</td>\n",
       "      <td>1.122547</td>\n",
       "      <td>0.744271</td>\n",
       "      <td>0.764912</td>\n",
       "      <td>-0.139230</td>\n",
       "      <td>-0.204473</td>\n",
       "      <td>0.564068</td>\n",
       "      <td>0.402104</td>\n",
       "      <td>-1.099772</td>\n",
       "      <td>-0.329863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265884</td>\n",
       "      <td>0.551817</td>\n",
       "      <td>-0.024144</td>\n",
       "      <td>0.013799</td>\n",
       "      <td>-0.193939</td>\n",
       "      <td>-0.331876</td>\n",
       "      <td>0.023635</td>\n",
       "      <td>0.092980</td>\n",
       "      <td>-0.079560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126193</th>\n",
       "      <td>-3.339192</td>\n",
       "      <td>1.370165</td>\n",
       "      <td>1.067984</td>\n",
       "      <td>-1.500224</td>\n",
       "      <td>-0.287427</td>\n",
       "      <td>0.172767</td>\n",
       "      <td>0.816022</td>\n",
       "      <td>-0.375759</td>\n",
       "      <td>0.778981</td>\n",
       "      <td>4.451948</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.250027</td>\n",
       "      <td>-1.383554</td>\n",
       "      <td>-0.211176</td>\n",
       "      <td>-0.397625</td>\n",
       "      <td>0.352532</td>\n",
       "      <td>0.021993</td>\n",
       "      <td>0.276908</td>\n",
       "      <td>0.054283</td>\n",
       "      <td>-0.153325</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253824</th>\n",
       "      <td>-0.670594</td>\n",
       "      <td>0.394768</td>\n",
       "      <td>0.923089</td>\n",
       "      <td>-0.752429</td>\n",
       "      <td>1.504524</td>\n",
       "      <td>0.708785</td>\n",
       "      <td>1.111056</td>\n",
       "      <td>-0.277891</td>\n",
       "      <td>0.319910</td>\n",
       "      <td>-0.297117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194003</td>\n",
       "      <td>1.173429</td>\n",
       "      <td>-0.462605</td>\n",
       "      <td>-0.935719</td>\n",
       "      <td>-0.027568</td>\n",
       "      <td>0.743513</td>\n",
       "      <td>-0.476945</td>\n",
       "      <td>-0.327464</td>\n",
       "      <td>-0.300934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80761</th>\n",
       "      <td>-1.795105</td>\n",
       "      <td>-1.494352</td>\n",
       "      <td>-0.537945</td>\n",
       "      <td>0.863900</td>\n",
       "      <td>-1.553549</td>\n",
       "      <td>1.518933</td>\n",
       "      <td>3.948610</td>\n",
       "      <td>-0.120538</td>\n",
       "      <td>-1.301061</td>\n",
       "      <td>-1.010590</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777665</td>\n",
       "      <td>0.705091</td>\n",
       "      <td>1.978397</td>\n",
       "      <td>-0.395184</td>\n",
       "      <td>-0.092714</td>\n",
       "      <td>-0.432663</td>\n",
       "      <td>-0.119388</td>\n",
       "      <td>0.224242</td>\n",
       "      <td>3.206027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268908</th>\n",
       "      <td>2.078239</td>\n",
       "      <td>0.144335</td>\n",
       "      <td>-1.729059</td>\n",
       "      <td>0.406886</td>\n",
       "      <td>0.426321</td>\n",
       "      <td>-0.854552</td>\n",
       "      <td>0.173452</td>\n",
       "      <td>-0.223779</td>\n",
       "      <td>0.522796</td>\n",
       "      <td>-0.373312</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.369914</td>\n",
       "      <td>-0.968218</td>\n",
       "      <td>0.335007</td>\n",
       "      <td>0.477426</td>\n",
       "      <td>-0.256684</td>\n",
       "      <td>0.175501</td>\n",
       "      <td>-0.063895</td>\n",
       "      <td>-0.031313</td>\n",
       "      <td>-0.345313</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279863</th>\n",
       "      <td>-1.927883</td>\n",
       "      <td>1.125653</td>\n",
       "      <td>-4.518331</td>\n",
       "      <td>1.749293</td>\n",
       "      <td>-1.566487</td>\n",
       "      <td>-2.010494</td>\n",
       "      <td>-0.882850</td>\n",
       "      <td>0.697211</td>\n",
       "      <td>-2.064945</td>\n",
       "      <td>-5.587794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.778584</td>\n",
       "      <td>-0.319189</td>\n",
       "      <td>0.639419</td>\n",
       "      <td>-0.294885</td>\n",
       "      <td>0.537503</td>\n",
       "      <td>0.788395</td>\n",
       "      <td>0.292680</td>\n",
       "      <td>0.147968</td>\n",
       "      <td>1.206024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280143</th>\n",
       "      <td>1.378559</td>\n",
       "      <td>1.289381</td>\n",
       "      <td>-5.004247</td>\n",
       "      <td>1.411850</td>\n",
       "      <td>0.442581</td>\n",
       "      <td>-1.326536</td>\n",
       "      <td>-1.413170</td>\n",
       "      <td>0.248525</td>\n",
       "      <td>-1.127396</td>\n",
       "      <td>-3.232153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370612</td>\n",
       "      <td>0.028234</td>\n",
       "      <td>-0.145640</td>\n",
       "      <td>-0.081049</td>\n",
       "      <td>0.521875</td>\n",
       "      <td>0.739467</td>\n",
       "      <td>0.389152</td>\n",
       "      <td>0.186637</td>\n",
       "      <td>-0.350191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280149</th>\n",
       "      <td>-0.676143</td>\n",
       "      <td>1.126366</td>\n",
       "      <td>-2.213700</td>\n",
       "      <td>0.468308</td>\n",
       "      <td>-1.120541</td>\n",
       "      <td>-0.003346</td>\n",
       "      <td>-2.234739</td>\n",
       "      <td>1.210158</td>\n",
       "      <td>-0.652250</td>\n",
       "      <td>-3.463891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751826</td>\n",
       "      <td>0.834108</td>\n",
       "      <td>0.190944</td>\n",
       "      <td>0.032070</td>\n",
       "      <td>-0.739695</td>\n",
       "      <td>0.471111</td>\n",
       "      <td>0.385107</td>\n",
       "      <td>0.194361</td>\n",
       "      <td>-0.041818</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281144</th>\n",
       "      <td>-3.113832</td>\n",
       "      <td>0.585864</td>\n",
       "      <td>-5.399730</td>\n",
       "      <td>1.817092</td>\n",
       "      <td>-0.840618</td>\n",
       "      <td>-2.943548</td>\n",
       "      <td>-2.208002</td>\n",
       "      <td>1.058733</td>\n",
       "      <td>-1.632333</td>\n",
       "      <td>-5.245984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583276</td>\n",
       "      <td>-0.269209</td>\n",
       "      <td>-0.456108</td>\n",
       "      <td>-0.183659</td>\n",
       "      <td>-0.328168</td>\n",
       "      <td>0.606116</td>\n",
       "      <td>0.884876</td>\n",
       "      <td>-0.253700</td>\n",
       "      <td>0.626302</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281674</th>\n",
       "      <td>1.991976</td>\n",
       "      <td>0.158476</td>\n",
       "      <td>-2.583441</td>\n",
       "      <td>0.408670</td>\n",
       "      <td>1.151147</td>\n",
       "      <td>-0.096695</td>\n",
       "      <td>0.223050</td>\n",
       "      <td>-0.068384</td>\n",
       "      <td>0.577829</td>\n",
       "      <td>-0.888722</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164350</td>\n",
       "      <td>-0.295135</td>\n",
       "      <td>-0.072173</td>\n",
       "      <td>-0.450261</td>\n",
       "      <td>0.313267</td>\n",
       "      <td>-0.289617</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>-0.015309</td>\n",
       "      <td>-0.183191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>984 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "109157 -0.652829  1.122547  0.744271  0.764912 -0.139230 -0.204473  0.564068   \n",
       "126193 -3.339192  1.370165  1.067984 -1.500224 -0.287427  0.172767  0.816022   \n",
       "253824 -0.670594  0.394768  0.923089 -0.752429  1.504524  0.708785  1.111056   \n",
       "80761  -1.795105 -1.494352 -0.537945  0.863900 -1.553549  1.518933  3.948610   \n",
       "268908  2.078239  0.144335 -1.729059  0.406886  0.426321 -0.854552  0.173452   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "279863 -1.927883  1.125653 -4.518331  1.749293 -1.566487 -2.010494 -0.882850   \n",
       "280143  1.378559  1.289381 -5.004247  1.411850  0.442581 -1.326536 -1.413170   \n",
       "280149 -0.676143  1.126366 -2.213700  0.468308 -1.120541 -0.003346 -2.234739   \n",
       "281144 -3.113832  0.585864 -5.399730  1.817092 -0.840618 -2.943548 -2.208002   \n",
       "281674  1.991976  0.158476 -2.583441  0.408670  1.151147 -0.096695  0.223050   \n",
       "\n",
       "              V8        V9       V10  ...       V21       V22       V23  \\\n",
       "109157  0.402104 -1.099772 -0.329863  ...  0.265884  0.551817 -0.024144   \n",
       "126193 -0.375759  0.778981  4.451948  ... -1.250027 -1.383554 -0.211176   \n",
       "253824 -0.277891  0.319910 -0.297117  ...  0.194003  1.173429 -0.462605   \n",
       "80761  -0.120538 -1.301061 -1.010590  ...  0.777665  0.705091  1.978397   \n",
       "268908 -0.223779  0.522796 -0.373312  ... -0.369914 -0.968218  0.335007   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "279863  0.697211 -2.064945 -5.587794  ...  0.778584 -0.319189  0.639419   \n",
       "280143  0.248525 -1.127396 -3.232153  ...  0.370612  0.028234 -0.145640   \n",
       "280149  1.210158 -0.652250 -3.463891  ...  0.751826  0.834108  0.190944   \n",
       "281144  1.058733 -1.632333 -5.245984  ...  0.583276 -0.269209 -0.456108   \n",
       "281674 -0.068384  0.577829 -0.888722  ... -0.164350 -0.295135 -0.072173   \n",
       "\n",
       "             V24       V25       V26       V27       V28  normAmount  Class  \n",
       "109157  0.013799 -0.193939 -0.331876  0.023635  0.092980   -0.079560      0  \n",
       "126193 -0.397625  0.352532  0.021993  0.276908  0.054283   -0.153325      0  \n",
       "253824 -0.935719 -0.027568  0.743513 -0.476945 -0.327464   -0.300934      0  \n",
       "80761  -0.395184 -0.092714 -0.432663 -0.119388  0.224242    3.206027      0  \n",
       "268908  0.477426 -0.256684  0.175501 -0.063895 -0.031313   -0.345313      0  \n",
       "...          ...       ...       ...       ...       ...         ...    ...  \n",
       "279863 -0.294885  0.537503  0.788395  0.292680  0.147968    1.206024      1  \n",
       "280143 -0.081049  0.521875  0.739467  0.389152  0.186637   -0.350191      1  \n",
       "280149  0.032070 -0.739695  0.471111  0.385107  0.194361   -0.041818      1  \n",
       "281144 -0.183659 -0.328168  0.606116  0.884876 -0.253700    0.626302      1  \n",
       "281674 -0.450261  0.313267 -0.289617  0.002988 -0.015309   -0.183191      1  \n",
       "\n",
       "[984 rows x 30 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample = pd.concat([df_class_0,df_class_1])\n",
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f6d5085b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(836, 29)\n",
      "(148, 29)\n"
     ]
    }
   ],
   "source": [
    "X =df_sample.values[:,0:29] #독립변수\n",
    "Y =df_sample.values[:,29] #종속변수 , 31만\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(X,Y, test_size = 0.15) #85 : 15니까\n",
    "print(X_train.shape) # 85프로\n",
    "print(X_test.shape) #15프로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "eed05c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5514 - accuracy: 0.7215 - val_loss: 0.4351 - val_accuracy: 0.8297\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.43507, saving model to ./credit_50\\01-0.4351.hdf5\n",
      "Epoch 2/1000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.8268 - val_loss: 0.3820 - val_accuracy: 0.8841\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.43507 to 0.38196, saving model to ./credit_50\\02-0.3820.hdf5\n",
      "Epoch 3/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4202 - accuracy: 0.8561 - val_loss: 0.3393 - val_accuracy: 0.9094\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.38196 to 0.33926, saving model to ./credit_50\\03-0.3393.hdf5\n",
      "Epoch 4/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3751 - accuracy: 0.8758 - val_loss: 0.3029 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.33926 to 0.30292, saving model to ./credit_50\\04-0.3029.hdf5\n",
      "Epoch 5/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3413 - accuracy: 0.8906 - val_loss: 0.2730 - val_accuracy: 0.9275\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.30292 to 0.27296, saving model to ./credit_50\\05-0.2730.hdf5\n",
      "Epoch 6/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3155 - accuracy: 0.9147 - val_loss: 0.2470 - val_accuracy: 0.9384\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.27296 to 0.24705, saving model to ./credit_50\\06-0.2470.hdf5\n",
      "Epoch 7/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2896 - accuracy: 0.9115 - val_loss: 0.2262 - val_accuracy: 0.9384\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.24705 to 0.22622, saving model to ./credit_50\\07-0.2262.hdf5\n",
      "Epoch 8/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2781 - accuracy: 0.9215 - val_loss: 0.2083 - val_accuracy: 0.9384\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.22622 to 0.20825, saving model to ./credit_50\\08-0.2083.hdf5\n",
      "Epoch 9/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2304 - accuracy: 0.9415 - val_loss: 0.1926 - val_accuracy: 0.9420\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.20825 to 0.19262, saving model to ./credit_50\\09-0.1926.hdf5\n",
      "Epoch 10/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2403 - accuracy: 0.9196 - val_loss: 0.1806 - val_accuracy: 0.9420\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.19262 to 0.18058, saving model to ./credit_50\\10-0.1806.hdf5\n",
      "Epoch 11/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2334 - accuracy: 0.9278 - val_loss: 0.1704 - val_accuracy: 0.9457\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.18058 to 0.17042, saving model to ./credit_50\\11-0.1704.hdf5\n",
      "Epoch 12/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1985 - accuracy: 0.9411 - val_loss: 0.1613 - val_accuracy: 0.9457\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.17042 to 0.16128, saving model to ./credit_50\\12-0.1613.hdf5\n",
      "Epoch 13/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.9295 - val_loss: 0.1552 - val_accuracy: 0.9384\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.16128 to 0.15517, saving model to ./credit_50\\13-0.1552.hdf5\n",
      "Epoch 14/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1954 - accuracy: 0.9194 - val_loss: 0.1499 - val_accuracy: 0.9420\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.15517 to 0.14989, saving model to ./credit_50\\14-0.1499.hdf5\n",
      "Epoch 15/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1689 - accuracy: 0.9347 - val_loss: 0.1447 - val_accuracy: 0.9493\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.14989 to 0.14471, saving model to ./credit_50\\15-0.1447.hdf5\n",
      "Epoch 16/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1515 - accuracy: 0.9541 - val_loss: 0.1400 - val_accuracy: 0.9493\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.14471 to 0.13995, saving model to ./credit_50\\16-0.1400.hdf5\n",
      "Epoch 17/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1650 - accuracy: 0.9368 - val_loss: 0.1373 - val_accuracy: 0.9493\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.13995 to 0.13728, saving model to ./credit_50\\17-0.1373.hdf5\n",
      "Epoch 18/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1585 - accuracy: 0.9427 - val_loss: 0.1361 - val_accuracy: 0.9565\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.13728 to 0.13607, saving model to ./credit_50\\18-0.1361.hdf5\n",
      "Epoch 19/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1512 - accuracy: 0.9360 - val_loss: 0.1333 - val_accuracy: 0.9565\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.13607 to 0.13326, saving model to ./credit_50\\19-0.1333.hdf5\n",
      "Epoch 20/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1477 - accuracy: 0.9460 - val_loss: 0.1307 - val_accuracy: 0.9565\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.13326 to 0.13065, saving model to ./credit_50\\20-0.1307.hdf5\n",
      "Epoch 21/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1253 - accuracy: 0.9475 - val_loss: 0.1293 - val_accuracy: 0.9565\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.13065 to 0.12932, saving model to ./credit_50\\21-0.1293.hdf5\n",
      "Epoch 22/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1365 - accuracy: 0.9500 - val_loss: 0.1287 - val_accuracy: 0.9565\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.12932 to 0.12872, saving model to ./credit_50\\22-0.1287.hdf5\n",
      "Epoch 23/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1365 - accuracy: 0.9444 - val_loss: 0.1274 - val_accuracy: 0.9565\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.12872 to 0.12744, saving model to ./credit_50\\23-0.1274.hdf5\n",
      "Epoch 24/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1621 - accuracy: 0.9319 - val_loss: 0.1281 - val_accuracy: 0.9601\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.12744\n",
      "Epoch 25/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1348 - accuracy: 0.9458 - val_loss: 0.1268 - val_accuracy: 0.9601\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.12744 to 0.12683, saving model to ./credit_50\\25-0.1268.hdf5\n",
      "Epoch 26/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1159 - accuracy: 0.9536 - val_loss: 0.1272 - val_accuracy: 0.9601\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.12683\n",
      "Epoch 27/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1209 - accuracy: 0.9564 - val_loss: 0.1281 - val_accuracy: 0.9601\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.12683\n",
      "Epoch 28/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1553 - accuracy: 0.9365 - val_loss: 0.1282 - val_accuracy: 0.9565\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.12683\n",
      "Epoch 29/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1273 - accuracy: 0.9452 - val_loss: 0.1283 - val_accuracy: 0.9601\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.12683\n",
      "Epoch 30/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9656 - val_loss: 0.1295 - val_accuracy: 0.9565\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.12683\n",
      "Epoch 31/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1413 - accuracy: 0.9286 - val_loss: 0.1296 - val_accuracy: 0.9601\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.12683\n",
      "Epoch 32/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1105 - accuracy: 0.9572 - val_loss: 0.1286 - val_accuracy: 0.9638\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.12683\n",
      "Epoch 33/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0863 - accuracy: 0.9709 - val_loss: 0.1289 - val_accuracy: 0.9638\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.12683\n",
      "Epoch 34/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1085 - accuracy: 0.9563 - val_loss: 0.1313 - val_accuracy: 0.9601\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.12683\n",
      "Epoch 35/1000\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0954 - accuracy: 0.9591 - val_loss: 0.1309 - val_accuracy: 0.9638\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.12683\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 14)                420       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 105       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 32        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 562\n",
      "Trainable params: 562\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#모델 설정\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(12, activation = 'tanh', input_dim=X.shape[1]))\n",
    "model_1.add(Dense(6, activation = 'relu'))\n",
    "model_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#모델 컴파일\n",
    "model_1.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics= ['accuracy'])\n",
    "\n",
    "#모델 저장 폴더 지정\n",
    "MODEL_DIR='./credit_50/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "\n",
    "#모델 저장 방법\n",
    "modelpath = './credit_50/{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "checkpointer =  ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    \n",
    "# 학습 조기 종료 , callbacks=[checkpointer, early_stopping_callback]\n",
    "early_stopping_callback= EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "\n",
    "# 모델 학습\n",
    "history = model_1.fit(X_train, Y_train ,validation_split=0.33, epochs=1000, batch_size=20,\n",
    "                    callbacks=[checkpointer, early_stopping_callback])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6b06c118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 반복횟수에 따른 정확도 및 loss를 그래프로 확인\n",
    "y_vloss = history.history['val_loss']\n",
    "y_acc = history.history['accuracy']\n",
    "\n",
    "x_len = np.arange(len(y_acc))\n",
    "\n",
    "plt.plot(x_len, y_vloss, 'o', c='red',markersize=3)\n",
    "plt.plot(x_len, y_acc, 'o', c='blue',markersize=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "54489731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 499us/step - loss: 0.1541 - accuracy: 0.9189\n",
      "[0.15406981110572815, 0.9189189076423645]\n",
      "가져올 데이터 번호21\n",
      "신용카드를 부정사용 확률은 12.731775641441345%입니다.\n"
     ]
    }
   ],
   "source": [
    "#학습기 불러오기\n",
    "from keras.models import load_model\n",
    "# model.save('09-0.0902.hdf5')\n",
    "model_1 = load_model('./credit_50/25-0.1268.hdf5')\n",
    "\n",
    "\n",
    "#평가\n",
    "print(model_1 .evaluate(X_test,Y_test))\n",
    "\n",
    "#예측\n",
    "prediction = model_1.predict(X_test)\n",
    "# print(prediction)\n",
    "부정자용자 =int(input('가져올 데이터 번호'))\n",
    "부정사용 = prediction[부정자용자]\n",
    "pirnt(부정사용)\n",
    "# p=부정사용[0]*100\n",
    "# print(f'신용카드를 부정사용 확률은 {p}%입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "aefb4253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148, 1)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_t = np.round(prediction)\n",
    "y_pred_t = y_pred_t.astype(int)\n",
    "y_pred_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "509e2756",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_t = Y_test.astype(int)\n",
    "Y_test_t = Y_test_t.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "df188d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148, 1)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8cf92b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8,  21,  22,  60,  77,  96,  98, 122, 125, 129, 132, 142],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측값과 실제값 다른것들만 들고와서 보여주기위함\n",
    "miss = np.where(Y_test_t != y_pred_t)[0]\n",
    "miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "48f15c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 몇개 잘못 분류 했나?\n",
    "len(miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d25c07a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21번째학습데이터의 True값은 : [1]인데, Predic값은 : [0]이다\n"
     ]
    }
   ],
   "source": [
    "i=np.random.choice(miss)\n",
    "print(\"%s번째학습데이터의 True값은 : %s인데, Predic값은 : %s이다\"%(i,Y_test_t[i],y_pred_t[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c0c788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
